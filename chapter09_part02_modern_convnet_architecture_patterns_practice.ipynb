{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RealTaeYoungKang/CAU-AI4DeepLearning/blob/main/chapter09_part02_modern_convnet_architecture_patterns_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi3Se85BeiR8"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4feJDEWeiR_"
      },
      "source": [
        "## Modern convnet architecture patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4YiXB5MeiR_"
      },
      "source": [
        "### Modularity, hierarchy, and reuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5PJveWXeiR_"
      },
      "source": [
        "### Residual connections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVa1EIP4eiSA"
      },
      "source": [
        "**Residual block where the number of filters changes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Qc5bnLZPeiSA"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
        "residual = x\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "residual = layers.Conv2D(64, 1)(residual) # resize 필요\n",
        "x = layers.add([x, residual])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
        "residual = x\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "residual = layers.Conv2D(64, 1)(residual) # resize 필요\n",
        "x = layers.add([x, residual])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "RUbwtUGif2cr",
        "outputId": "90430ff6-31f4-4042-c121-af641e60f05e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Inputs have incompatible shapes. Received shapes (30, 30, 32) and (30, 30, 64)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-8281c672e606>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# resize 필요\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/merging/add.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(inputs, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/merging/base_merge.py\u001b[0m in \u001b[0;36m_compute_elemwise_op_output_shape\u001b[0;34m(self, shape1, shape2)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m     75\u001b[0m                         \u001b[0;34m\"Inputs have incompatible shapes. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                         \u001b[0;34mf\"Received shapes {shape1} and {shape2}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Inputs have incompatible shapes. Received shapes (30, 30, 32) and (30, 30, 64)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsY7c_O4eiSB"
      },
      "source": [
        "**Case where target block includes a max pooling layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pg0OCgZGeiSB"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
        "residual = x\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
        "residual = layers.Conv2D(64, 1, strides=2)(residual)\n",
        "x = layers.add([x, residual])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ah5lXJpBeiSC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f6a738-08e7-4da4-f051-b6f92332b0e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)       (None, 32, 32, 3)            0         ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 32)           896       ['rescaling[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 32)           9248      ['conv2d_6[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 16, 16, 32)           0         ['conv2d_7[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 32)           128       ['rescaling[0][0]']           \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 16, 16, 32)           0         ['max_pooling2d_1[0][0]',     \n",
            "                                                                     'conv2d_8[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 64)           18496     ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_9[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 8, 8, 64)             0         ['conv2d_10[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 64)             2112      ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 8, 8, 64)             0         ['max_pooling2d_2[0][0]',     \n",
            "                                                                     'conv2d_11[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 8, 8, 128)            73856     ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_12[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 8, 8, 128)            8320      ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 8, 8, 128)            0         ['conv2d_13[0][0]',           \n",
            "                                                                     'conv2d_14[0][0]']           \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 128)                  0         ['add_4[0][0]']               \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 1)                    129       ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 297697 (1.14 MB)\n",
            "Trainable params: 297697 (1.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "\n",
        "def residual_block(x, filters, pooling=False):\n",
        "    residual = x\n",
        "    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    if pooling:\n",
        "        x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
        "        residual = layers.Conv2D(filters, 1, strides=2)(residual)\n",
        "    elif filters != residual.shape[-1]:\n",
        "        residual = layers.Conv2D(filters, 1)(residual)\n",
        "    x = layers.add([x, residual])\n",
        "    return x\n",
        "\n",
        "x = residual_block(x, filters=32, pooling=True)\n",
        "x = residual_block(x, filters=64, pooling=True)\n",
        "x = residual_block(x, filters=128, pooling=False)\n",
        "\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjctwjzCeiSC"
      },
      "source": [
        "### Batch normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAAd1CmBeiSC"
      },
      "source": [
        "### Depthwise separable convolutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzu50h_2eiSC"
      },
      "source": [
        "### Putting it together: A mini Xception-like model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "gdown.download(id='18uC7WTuEXKJDDxbj-Jq6EjzpFrgE7IAd', output='dogs-vs-cats.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "FoX1trKlgPxe",
        "outputId": "0f7389c3-0f0f-4df1-fcca-09eb5f64cf50"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=18uC7WTuEXKJDDxbj-Jq6EjzpFrgE7IAd\n",
            "From (redirected): https://drive.google.com/uc?id=18uC7WTuEXKJDDxbj-Jq6EjzpFrgE7IAd&confirm=t&uuid=2e6365f4-5e22-46a5-9763-7fd2065aa175\n",
            "To: /content/dogs-vs-cats.zip\n",
            "100%|██████████| 852M/852M [00:16<00:00, 52.5MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dogs-vs-cats.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq dogs-vs-cats.zip\n",
        "\n",
        "!unzip -qq train.zip"
      ],
      "metadata": {
        "id": "DIMPpzzMgRg5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ii8nJYEFeiSC"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FGQ-_ShveiSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "378e3355-04eb-434c-b620-602a2c33b8a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/__init__.py\", line 7, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\", line 398, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n",
            "replace train/cat.0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c dogs-vs-cats\n",
        "!unzip -qq train.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NO1g5MVoeiSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f85e54c-5ef6-4ad7-a86a-3f554fc5a8fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 2000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import os, shutil, pathlib\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n",
        "\n",
        "make_subset(\"train\", start_index=0, end_index=1000)\n",
        "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
        "make_subset(\"test\", start_index=1500, end_index=2500)\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IaKmdp2EeiSD"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qLajsVRweiSD"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=5, use_bias=False)(x)\n",
        "\n",
        "for size in [32, 64, 128, 256, 512]:\n",
        "    residual = x\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
        "\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "    residual = layers.Conv2D(\n",
        "        size, 1, strides=2, padding=\"same\", use_bias=False)(residual)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CT0DdLVteiSE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7ac88ea-7beb-4194-e930-837943011d25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "63/63 [==============================] - 10s 88ms/step - loss: 0.6203 - accuracy: 0.6705 - val_loss: 0.7106 - val_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.5992 - accuracy: 0.6790 - val_loss: 0.7444 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.6002 - accuracy: 0.6940 - val_loss: 0.7756 - val_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.5704 - accuracy: 0.7035 - val_loss: 1.0380 - val_accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.5639 - accuracy: 0.7215 - val_loss: 0.8661 - val_accuracy: 0.5160\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 5s 84ms/step - loss: 0.5318 - accuracy: 0.7300 - val_loss: 0.8201 - val_accuracy: 0.5480\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.5339 - accuracy: 0.7360 - val_loss: 0.7196 - val_accuracy: 0.6060\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.5193 - accuracy: 0.7505 - val_loss: 0.5027 - val_accuracy: 0.7570\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.5105 - accuracy: 0.7495 - val_loss: 2.3790 - val_accuracy: 0.5050\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.4812 - accuracy: 0.7835 - val_loss: 0.7118 - val_accuracy: 0.6490\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.4755 - accuracy: 0.7820 - val_loss: 0.4841 - val_accuracy: 0.7670\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.4682 - accuracy: 0.7890 - val_loss: 1.0288 - val_accuracy: 0.6540\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.4465 - accuracy: 0.7980 - val_loss: 0.7870 - val_accuracy: 0.6220\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.4243 - accuracy: 0.8110 - val_loss: 0.4994 - val_accuracy: 0.7670\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.4236 - accuracy: 0.8030 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.4064 - accuracy: 0.8270 - val_loss: 0.5780 - val_accuracy: 0.6670\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.4177 - accuracy: 0.8115 - val_loss: 1.0263 - val_accuracy: 0.5960\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.3845 - accuracy: 0.8275 - val_loss: 0.7097 - val_accuracy: 0.6550\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.3939 - accuracy: 0.8315 - val_loss: 0.5049 - val_accuracy: 0.7560\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.3725 - accuracy: 0.8440 - val_loss: 0.4845 - val_accuracy: 0.7690\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.3769 - accuracy: 0.8370 - val_loss: 1.1893 - val_accuracy: 0.6850\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(patience = 10)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=100,\n",
        "    validation_data=validation_dataset, callbacks = [early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8uwE_xZge-Fm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}